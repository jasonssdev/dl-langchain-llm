{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98af7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python dot env\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import SecretStr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a351f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load environment variables\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40aa25db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Missing OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42b6ea5",
   "metadata": {},
   "source": [
    "# Open AI Implementatino VS Langchain implemenmtation with functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276d39af",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b09f92cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Me encanta pinchar.\\n\\nIf you want to emphasize being a DJ, you could also say: Me encanta ser DJ.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "# create client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "# create function\n",
    "def get_response_openai(input: list, model: str = 'gpt-5-nano') -> str:\n",
    "    response = client.responses.create(\n",
    "        model=model,\n",
    "        input=input,\n",
    "        )\n",
    "    return response.output_text\n",
    "\n",
    "\n",
    "def get_translation_openai(input_language: str, output_language: str, input_text: str) -> str:\n",
    "    messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that translates text.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Translate the following text from {input_language} to {output_language}: {input_text}.\"\n",
    "    }\n",
    "]\n",
    "    response = get_response_openai(messages)\n",
    "    return response\n",
    "\n",
    "\n",
    "get_translation_openai(\"English\", \"Spanish\", \"I love djing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa3bb11",
   "metadata": {},
   "source": [
    "## Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6830228a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Me encanta pinchar.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-mini\", temperature=0.0)\n",
    "\n",
    "\n",
    "def get_translation_langchain(input_language, output_language, input_text):\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant that translates {input_language} to {output_language}.\"),\n",
    "        (\"human\", \"{input_text}\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt_template | llm\n",
    "\n",
    "    response = chain.invoke({\n",
    "        \"input_language\": input_language,\n",
    "        \"output_language\": output_language,\n",
    "        \"input_text\": input_text\n",
    "    })\n",
    "\n",
    "    return response.content\n",
    "\n",
    "get_translation_langchain(\"English\", \"Spanish\", \"I love djing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc2668b",
   "metadata": {},
   "source": [
    "## Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "baed5b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "def get_parser_review(review):\n",
    "    llm = ChatOpenAI(model=\"gpt-5-mini\", temperature=0.0)\n",
    "\n",
    "    gift_schema = ResponseSchema(\n",
    "        name=\"gift\",\n",
    "        description=(\"Was the item purchased as a gift for someone else? \"\n",
    "                    \"Answer True if yes, False if not or unknown.\")\n",
    "    )\n",
    "    delivery_days_schema = ResponseSchema(\n",
    "        name=\"delivery_days\",\n",
    "        description=(\"How many days did it take for the product to arrive? \"\n",
    "                    \"If this information is not found, output -1.\")\n",
    "    )\n",
    "    price_value_schema = ResponseSchema(\n",
    "        name=\"price_value\",\n",
    "        description=(\"Extract any sentences about the value or price, and output them as a comma separated Python list.\")\n",
    "    )\n",
    "\n",
    "    response_schemas = [gift_schema, delivery_days_schema, price_value_schema]\n",
    "\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You extract structured fields from a product review.\"),\n",
    "        (\"human\",\n",
    "        \"Review:\\n{review}\\n\\n\"\n",
    "        \"Return ONLY the data following these format rules:\\n{format_instructions}\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    response = chain.invoke({\n",
    "        \"review\": review,\n",
    "        \"format_instructions\": format_instructions\n",
    "    })\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6cb8f520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gift': 'True', 'delivery_days': '2', 'price_value': '[\"It\\'s slightly more expensive than the other leaf blowers out there, but I think it\\'s worth it for the extra features.\"]'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "output = get_parser_review(customer_review)\n",
    "print(output)\n",
    "print(type(output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
